% !Mode:: "TeX:UTF-8"

%%  可通过增加或减少 setup/format.tex中的
%%  第274行 \setlength{\@title@width}{8cm}中 8cm 这个参数来 控制封面中下划线的长度。

\cheading{天津大学~2018~届本科生毕业论文}      % 设置正文的页眉，需要填上对应的毕业年份
\ctitle{基于强化学习的文本匹配}    % 封面用论文标题，自己可手动断行
\caffil{计算机科学与技术学院} % 学院名称
\csubject{计算机科学与技术学院}   % 专业名称
\cgrade{2014级}            % 年级
\cauthor{陶舒畅}            % 学生姓名
\cnumber{3014216073}        % 学生学号
\csupervisor{张鹏副教授}        % 导师姓名
\crank{副教授}              % 导师职称

\cdate{\the\year~年~\the\month~月~\the\day~日}

\cabstract{
随着计算机和互联网的飞速发展，互联网的信息量呈现爆炸式增长。在海量的信息面前如何高效的获取信息以及如何去除冗余信息日益受到大家关注。文本匹配作为信息检索和冗余文本消除的基础技术手段，一直受到学术界和工业界的高度重视。

目前对文本匹配的研究大都通过深度神经网络进行语义匹配。近年来，深度学习的进展大大增强了强化学习的表达能力。利用强化学习方法，可在较少的计算量下得到更好的效果。

本文主要的研究内容包括:

(1) 本文设计并实现基于强化学习的文本匹配算法，设计了强化学习中的状态、动作以及奖励函数，并基于值迭代算法进行实现求解。在大数据集的各个评价准则下均优于其他经典文本匹配算法的效果。

(2) 基于值迭代的文本匹配模型是基于贪心的方法，对于语言的组合结构问题可能会出现局部最优解。本文基于蒙特卡罗树搜索算法设计了文本匹配模型，并与其他经典算法进行了对比。实现结果表明，基于蒙特卡罗树搜索的文本匹配模型具有显著的优势。

}

\ckeywords{文本匹配；强化学习；马尔科夫决策过程；蒙特卡洛树搜索}

\eabstract{
With the development of computer science and Internet, the amount of information is growing rapidly.  How to obtain information efficiently and remove redundant one among the massive information have become a problem that many people have to face. Text matching, as a basic technology for information retrieval and redundant text elimination, is widely used in the academic community and industry. At the same time, many tasks in natural language processing such as information retrieval, question answering systems, machine translation, dialogue systems, etc., can be considered as text matching problems.

Recently, the researches on text matching mostly concentrate on understanding text semantics by deep neural networks for semantic matching. Nowadays reinforcement learning enhanced by deep learning methods has a stronger express ability. We can get better result with less calculation amount by reinforcement learning.

In this paper, we found the main issues in the text matching based on reinforcement learning are:

(1) We design and implement reinforcement learning process for text matching. We proposes a new reinforcement learning method with well-designed states, actions and reward function to tackle text matching problem, and implements solution based on value iterative algorithms. The reinforcement learning algorithm designed in this paper is superior to other classic text matching methods under the various evaluation criteria in large data set scenarios.

(2)The value-iteration-based text matching model is a greedy method. Local optimal solutions may appear for the linguistic compositional structure problem. This paper proposes a text matching model based on Monte Carlo search algorithm and compares it with other classical algorithms. The results show that the text matching model based on Monte Carlo search outperforms others.


}

\ekeywords{Text Matching, Reinforcement learning, Markov Decision Process, Monte Carlo Tree Search}

\makecover

\clearpage
